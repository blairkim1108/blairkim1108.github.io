[
  {
    "objectID": "valentine.html",
    "href": "valentine.html",
    "title": "valentine",
    "section": "",
    "text": "# tidytuesdayR package \n## install.packages(\"tidytuesdayR\")\n\ntuesdata &lt;- tidytuesdayR::tt_load('2024-02-13')\n\nhistorical_spending &lt;- tuesdata$historical_spending\ngifts_age &lt;- tuesdata$gifts_age\ngifts_gender &lt;- tuesdata$gifts_gender\n\n\n# packages\nlibrary(tidyverse)\n\n\n# popular gift on valentine's day by year \n\n ggplot(historical_spending, aes(x = Year)) +\n  geom_line(aes(y = Flowers, color = \"Flowers\")) +\n  geom_line(aes(y = Candy, color = \"Candy\")) +\n  geom_line(aes(y = Jewelry, color = \"Jewelry\")) +\n  labs(\n    x = \"Year\",\n    y = \"Average Percent Spending\",\n    title = \"Popular gift on Valentine's Day\",\n    color = \"Gift Type\")\n\n\n\n\n\n\n\n\n(Harmon and Hughes 2024)\n\n\n\n\n\n\nNote\n\n\n\nOriginal data from https://www.kaggle.com/datasets/infinator/happy-valentines-day-2022\n\n\n\n\n\n\nReferences\n\nHarmon, Jon, and Ellis Hughes. 2024. “tidytuesdayR: Access the Weekly ’TidyTuesday’ Project Dataset.” https://CRAN.R-project.org/package=tidytuesdayR."
  },
  {
    "objectID": "project3.html",
    "href": "project3.html",
    "title": "Project 3",
    "section": "",
    "text": "In this project, I plan to test if the gender gap in salary is real, or just by random chance. In order to do this, I found a dataset online that has information about the salaries of employees at a company with their gender, age, years of experience, education level, and job title. To investigate whether gender affects employee salaries, I will shuffle the gender labels multiple times, calculating the difference in mean salaries each time to create a null distribution, and compare it to the observed difference.\n\n# packages\nlibrary(tidyverse)\nlibrary(ggplot2)\n\n\n# import dataset \nsalary &lt;- read.csv(\"Salary Data.csv\")\n\n# data cleaning \nsalary_clean &lt;- salary |&gt; filter(!is.na(Age))\n\n\n# averages and median salary between men and women\n\nsalary_clean |&gt;\n  group_by(Gender) |&gt;\n  summarize(ave_salary = mean(Salary),\n            med_salary = median(Salary)) |&gt;\n  summarize(ave_diff = diff(ave_salary),\n            med_diff = diff(med_salary))\n\n# A tibble: 1 × 2\n  ave_diff med_diff\n     &lt;dbl&gt;    &lt;dbl&gt;\n1    6857.     7500\n\n\n\n# generate a null sampling distribution \nperm_data &lt;- function(rep, data){\n  salary_clean |&gt; \n    select(Gender, Salary) |&gt; \n    mutate(salary_perm = sample(Salary, replace = FALSE)) |&gt; \n    group_by(Gender) |&gt; \n    summarize(obs_ave = mean(Salary),\n              obs_med = median(Salary),\n              perm_ave = mean(salary_perm),\n              perm_med = median(salary_perm)) |&gt; \n    summarize(obs_ave_diff = diff(obs_ave),\n              obs_med_diff = diff(obs_med),\n              perm_ave_diff = diff(perm_ave),\n              perm_med_diff = diff(perm_med),\n              rep = rep)\n}\n\n\nmap(c(1:10), perm_data, data = Salary) |&gt; \n  list_rbind()\n\n# A tibble: 10 × 5\n   obs_ave_diff obs_med_diff perm_ave_diff perm_med_diff   rep\n          &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt; &lt;int&gt;\n 1        6857.         7500       -9366.              0     1\n 2        6857.         7500       -1522.              0     2\n 3        6857.         7500          89.6             0     3\n 4        6857.         7500       -6033.          -5000     4\n 5        6857.         7500        4655.              0     5\n 6        6857.         7500       -4264.              0     6\n 7        6857.         7500        -125.              0     7\n 8        6857.         7500       -1686.              0     8\n 9        6857.         7500       -4318.              0     9\n10        6857.         7500        -612.              0    10\n\n\n\n# visualize the null sampling distribution\nset.seed(1108)\n\nperm_stats &lt;- map(c(1:500), perm_data, data = salary_clean) |&gt;\n  list_rbind() \n\n# average\nperm_stats |&gt; \n  ggplot(aes(x = perm_ave_diff)) + \n  geom_histogram() + \n  geom_vline(aes(xintercept = obs_ave_diff), color = \"red\")\n\n\n\n\n\n\n\n  labs()\n\nnamed list()\nattr(,\"class\")\n[1] \"labels\"\n\n# median\nperm_stats |&gt;\n  ggplot(aes(x = perm_med_diff)) +\n  geom_histogram() +\n  geom_vline(aes(xintercept = obs_med_diff), color = \"red\")\n\n\n\n\n\n\n\n  labs()\n\nnamed list()\nattr(,\"class\")\n[1] \"labels\"\n\n\n\n# p_value\nperm_stats |&gt; \n  summarize(p_val_ave = mean(perm_ave_diff &gt; obs_ave_diff),\n            p_val_med = mean(perm_med_diff &gt; obs_med_diff))\n\n# A tibble: 1 × 2\n  p_val_ave p_val_med\n      &lt;dbl&gt;     &lt;dbl&gt;\n1     0.078      0.08\n\n\nConclusion\n\nThe observed differences are consistent with the distribution of differences in the null sampling distribution. Based on the p-values (0.078 for the average salary and 0.08 for the median salary), we fail to reject the null hypothesis. This means there isn't enough evidence to claim that, in the population, the average salary of male employees is larger than that of female employees. Similarly, we cannot claim that the median salary of male employees is larger than the median salary of female employees. Both p-values suggest that the observed differences are likely due to random chance rather than a significant difference between the two groups.\nSource: Kiattisak Rattanaporn, Salary Prediction dataset from\nhttps://www.kaggle.com/datasets/rkiattisak/salaly-prediction-for-beginer?resource=download"
  },
  {
    "objectID": "simpsons.html",
    "href": "simpsons.html",
    "title": "simpsons",
    "section": "",
    "text": "install.packages(\"tidytuesdayR\", repos = \"https://cloud.r-project.org/\")\n\n\nThe downloaded binary packages are in\n    /var/folders/vg/12r57nf51593b_d4zr1kvcgw0000gn/T//RtmptLUWgG/downloaded_packages\n\nlibrary(\"tidytuesdayR\")\n\n\n###_____________________________________________________________________________\n### The Simpson's data!\n### Script to clean the data sourced from Kaggle\n###_____________________________________________________________________________\n\n# packages\nlibrary(httr)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(jsonlite)\n\n\nAttaching package: 'jsonlite'\n\nThe following object is masked from 'package:purrr':\n\n    flatten\n\nlibrary(withr)\n\n# Define the metadata URL and fetch it\nmetadata_url &lt;- \"www.kaggle.com/datasets/prashant111/the-simpsons-dataset/croissant/download\"\nresponse &lt;- httr::GET(metadata_url)\n\n# Ensure the request succeeded\nif (httr::http_status(response)$category != \"Success\") {\n  stop(\"Failed to fetch metadata.\")\n}\n\n# Parse the metadata\nmetadata &lt;- httr::content(response, as = \"parsed\", type = \"application/json\")\n\n# Locate the ZIP file URL\ndistribution &lt;- metadata$distribution\nzip_url &lt;- NULL\n\nfor (file in distribution) {\n  if (file$encodingFormat == \"application/zip\") {\n    zip_url &lt;- file$contentUrl\n    break\n  }\n}\n\nif (is.null(zip_url)) {\n  stop(\"No ZIP file URL found in the metadata.\")\n}\n\n# Download the ZIP file. We'll use the withr package to make sure the downloaded\n# files get cleaned up when we're done.\ntemp_file &lt;- withr::local_tempfile(fileext = \".zip\") \nutils::download.file(zip_url, temp_file, mode = \"wb\")\n\n# Unzip and read the CSV\nunzip_dir &lt;- withr::local_tempdir()\nutils::unzip(temp_file, exdir = unzip_dir)\n\n# Locate the CSV file within the extracted contents\ncsv_file &lt;- list.files(unzip_dir, pattern = \"\\\\.csv$\", full.names = TRUE)\n\nif (length(csv_file) == 0) {\n  stop(\"No CSV file found in the unzipped contents.\")\n}\n\n# Read the CSV into a dataframe\nsimpsons_characters &lt;- read_csv(csv_file[1])\n\nRows: 6722 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): name, normalized_name, gender\ndbl (1): id\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsimpsons_episodes &lt;- read_csv(csv_file[2])\n\nRows: 600 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): image_url, production_code, title, video_url\ndbl  (9): id, imdb_rating, imdb_votes, number_in_season, number_in_series, o...\ndate (1): original_air_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsimpsons_locations &lt;- read_csv(csv_file[3])\n\nRows: 4459 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): name, normalized_name\ndbl (1): id\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsimpsons_script_lines &lt;- read_csv(csv_file[4])\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 158271 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): raw_text, raw_character_text, raw_location_text, spoken_words, norm...\ndbl (7): id, episode_id, number, timestamp_in_ms, character_id, location_id,...\nlgl (1): speaking_line\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Step 5: Explore the data\nglimpse(simpsons_characters)\n\nRows: 6,722\nColumns: 4\n$ id              &lt;dbl&gt; 7, 12, 13, 16, 20, 24, 26, 27, 29, 30, 34, 35, 36, 37,…\n$ name            &lt;chr&gt; \"Children\", \"Mechanical Santa\", \"Tattoo Man\", \"DOCTOR …\n$ normalized_name &lt;chr&gt; \"children\", \"mechanical santa\", \"tattoo man\", \"doctor …\n$ gender          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\nglimpse(simpsons_episodes)\n\nRows: 600\nColumns: 14\n$ id                     &lt;dbl&gt; 10, 12, 14, 17, 19, 21, 23, 26, 28, 30, 32, 35,…\n$ image_url              &lt;chr&gt; \"http://static-media.fxx.com/img/FX_Networks_-_…\n$ imdb_rating            &lt;dbl&gt; 7.4, 8.3, 8.2, 8.1, 8.0, 8.4, 7.8, 8.0, 8.2, 7.…\n$ imdb_votes             &lt;dbl&gt; 1511, 1716, 1638, 1457, 1366, 1522, 1340, 1329,…\n$ number_in_season       &lt;dbl&gt; 10, 12, 1, 4, 6, 8, 10, 13, 15, 17, 19, 22, 2, …\n$ number_in_series       &lt;dbl&gt; 10, 12, 14, 17, 19, 21, 23, 26, 28, 30, 32, 35,…\n$ original_air_date      &lt;date&gt; 1990-03-25, 1990-04-29, 1990-10-11, 1990-11-01…\n$ original_air_year      &lt;dbl&gt; 1990, 1990, 1990, 1990, 1990, 1990, 1991, 1991,…\n$ production_code        &lt;chr&gt; \"7G10\", \"7G12\", \"7F03\", \"7F01\", \"7F08\", \"7F06\",…\n$ season                 &lt;dbl&gt; 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,…\n$ title                  &lt;chr&gt; \"Homer's Night Out\", \"Krusty Gets Busted\", \"Bar…\n$ us_viewers_in_millions &lt;dbl&gt; 30.3, 30.4, 33.6, 26.1, 25.4, 26.2, 24.8, 26.2,…\n$ video_url              &lt;chr&gt; \"http://www.simpsonsworld.com/video/27519750787…\n$ views                  &lt;dbl&gt; 50816, 62561, 59575, 64959, 50691, 57605, 56486…\n\nglimpse(simpsons_locations)\n\nRows: 4,459\nColumns: 3\n$ id              &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ name            &lt;chr&gt; \"Street\", \"Car\", \"Springfield Elementary School\", \"Aud…\n$ normalized_name &lt;chr&gt; \"street\", \"car\", \"springfield elementary school\", \"aud…\n\nglimpse(simpsons_script_lines)\n\nRows: 158,271\nColumns: 13\n$ id                 &lt;dbl&gt; 9549, 9550, 9551, 9552, 9553, 9554, 9555, 9556, 955…\n$ episode_id         &lt;dbl&gt; 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,…\n$ number             &lt;dbl&gt; 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 2…\n$ raw_text           &lt;chr&gt; \"Miss Hoover: No, actually, it was a little of both…\n$ timestamp_in_ms    &lt;dbl&gt; 848000, 856000, 856000, 864000, 864000, 877000, 881…\n$ speaking_line      &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FAL…\n$ character_id       &lt;dbl&gt; 464, 9, 464, 9, 40, 38, 40, 8, NA, 9, 469, 9, 469, …\n$ location_id        &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 374, 374, 374, 374, 374, 37…\n$ raw_character_text &lt;chr&gt; \"Miss Hoover\", \"Lisa Simpson\", \"Miss Hoover\", \"Lisa…\n$ raw_location_text  &lt;chr&gt; \"Springfield Elementary School\", \"Springfield Eleme…\n$ spoken_words       &lt;chr&gt; \"No, actually, it was a little of both. Sometimes w…\n$ normalized_text    &lt;chr&gt; \"no actually it was a little of both sometimes when…\n$ word_count         &lt;dbl&gt; 31, 3, 22, 5, 33, 8, 1, 5, NA, 4, 19, 8, 10, 9, 19,…\n\n###_____________________________________________________________________________\n# Problems with the Data!\n\n# The script lines are of great interest, but it is a larger file, too big\n# for Tidy Tuesday.  We need to reduce the size of the file so we can use all\n# the files together for a more robust analysis.\n# Let's filter episodes down to the years 2010-2016, and then only select\n# the script lines that correspond with those episodes.\n\n###_____________________________________________________________________________\n\n# filter episodes to include 2010+\nsimpsons_episodes &lt;- simpsons_episodes |&gt; \n  dplyr::filter(original_air_year &gt;= 2010)\n\n# filter script lines to only include lines for these episodes\nsimpsons_script_lines &lt;- simpsons_script_lines |&gt; \n  dplyr::semi_join(simpsons_episodes, by = c(\"episode_id\" = \"id\"))\n\n\n# simpsons ratings by seasons\n ggplot(simpsons_episodes, aes(x = original_air_year, y = imdb_rating)) +\n       geom_point() +\n      geom_smooth(se = FALSE) +\n      labs(\n        x = \"air year\",\n        y = \"rating\",\n        title = \"Simpsons rating by year\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 3 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 3 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n(Harmon and Hughes 2024)\n\n\n\n\n\n\nNote\n\n\n\nOriginal data from https://www.kaggle.com/datasets/prashant111/the-simpsons-dataset\n\n\n\n\n\n\nReferences\n\nHarmon, Jon, and Ellis Hughes. 2024. “tidytuesdayR: Access the Weekly ’TidyTuesday’ Project Dataset.” https://CRAN.R-project.org/package=tidytuesdayR."
  },
  {
    "objectID": "theoffice.html",
    "href": "theoffice.html",
    "title": "theoffice",
    "section": "",
    "text": "# Get the Data\n\nthe_office_lines &lt;- read.csv(\"the-office_lines.csv\")\n\n\n# install packages \nlibrary(stringr)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n\n# Who says \"hey\" the most in the Office by season? \n\n\nmain_characters &lt;- c('Pam', 'Jim', 'Michael', 'Dwight', 'Ryan', 'Andy')\n\n\nhey_by_character &lt;- the_office_lines |&gt; \n  mutate(line_lower = tolower(Line)) |&gt; \n  filter(str_detect(line_lower, \"hey\")) |&gt; \n  group_by(Season, Character) |&gt; \n  summarize(count = n(), .groups = \"drop\") |&gt;\n  filter(Character %in% main_characters)\n\nggplot(hey_by_character, aes(x = Season, y = count, color = Character)) + \n  geom_point()+\n  labs(x = 'Season', y = 'Count',\n       title = 'Who says \"hey\" the most in each season of The Office?') +\n    scale_x_continuous(breaks=c(1:10))\n\n\n\n\n\n\n\n\nMichael says “hey” the most, and he really peaked in season 2 to 6.\n\n# Damn it Who? \n\nthe_office_lines_lower &lt;- \n  mutate(the_office_lines, line_lower = tolower(Line))\n\n\ndamn_it &lt;- \"damn it*\\\\s*(\\\\w+)\"\n\nthe_office_damnit &lt;- the_office_lines_lower |&gt;\n  mutate(character_damn_it = str_match(line_lower, damn_it) [ ,2])  \n\ndamn_it_counts &lt;- the_office_damnit |&gt; \n  filter(!is.na(character_damn_it)) |&gt;\n  group_by(Character) |&gt;\n  summarize(count=n()) |&gt;\n  slice_max(count, n = 10)\n\ndamn_it_counts |&gt;\n  ggplot(aes(x = Character, y = count)) +\n  geom_point() +\n  labs(\n    title = \"Damn it who?\",\n    x = \"Character\",\n    y = \"Count\",\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nDamn it, Dwight! Dwight is the character whose name is mentioned the most after the phrase “damn it”.\nSource: https://www.kaggle.com/datasets/fabriziocominetti/the-office-lines/data"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "blairkim1108.github.io",
    "section": "",
    "text": "This is a Quarto website."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]